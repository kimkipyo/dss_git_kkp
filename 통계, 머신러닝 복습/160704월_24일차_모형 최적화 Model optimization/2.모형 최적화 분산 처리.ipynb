{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모형 최적화 분산 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ipyparallel\n",
    "\n",
    "* http://ipyparallel.readthedocs.org/en/latest/index.html\n",
    "\n",
    "\n",
    "* Engine <-> Client\n",
    " * Engine: 실제 계산이 실행되는 프로세스\n",
    " * Client: 엔진을 제어하기 위한 인터페이스\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ conda install ipyparallel\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engine 가동/중지\n",
    "\n",
    "* 가동\n",
    "```\n",
    "$ ipcluster start -n 4\n",
    "```\n",
    "\n",
    "* 중지\n",
    " * Control-C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 코어가 1개당 워커는 1개로 지정. 8개라고 해서 8개 다 돌리면 안 된다.\n",
    "* 프론트엔드를 가진 프로그램이 있고 가지지 않은 프로그램이 있다.\n",
    "* 코어가 1개면 무의미. 코어가 여러개 있을 경우에 Ipython Clusters에서 engines을 여러개로 동시에 돌릴 수 있다.\n",
    "* 프론트엔드? 일반적으로 프론트엔드와 벡엔드라는 용어는 프로세스의 처음과 마지막 단계를 가리킨다. 프론트엔드는 사용자로부터 다양한 형태의 입력을 받아 벡엔드가 사용할 수 있는 규격을 따라 처리할 책임을 진다. 프론트엔드 개발자는 사용자가 접하게 되는 외적 부분의 구성 및 기능 구현에 중점을 두는 개발자, 백엔드개발자는 DB나 서버처럼 사용자가 접하지 않는 부분의 내부 지원을 담당하는 개발자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 원래 크롤링은 동시에 수백개를 돌린다는 의미다. 크롤링 할 수 있는 것은 scrapy가 파이썬에서 유일하다.\n",
    "* 그런데 이거 왜 안 배웠지? scrapy 설정을 잘 해야 한다. 안 그러면 디도스로 판단되어 막혀버린다.\n",
    "* 중간에 어디다가 저장하는 것이 파싱? LXML? BS는 너무 느려서 사실 잘 안 쓰인다. 스크래피는 자체 파서가 있다. 그래서 그걸 쓰면 된다.\n",
    "* XPath? [@id=\"comment_wrapper\"]/div[2]/div/div[2] 이런식으로 복사해서 쓰면 된다.\n",
    "* CSS selecter 문법과 유사하다.\n",
    "* robots.txt에서 크롤링해도 된다. 안된다가 나온다. 법적으로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipyparallel import Client\n",
    "c = Client()\n",
    "c.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DirectView [0, 1, 2, 3]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dview = c[:]\n",
    "dview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map / Reduce   \n",
    "빅데이터 할 때 듣는 용어. 분산처리 할 때\n",
    "* `map(function, data)`: data 각각에 function을 실행하여 결과 출력. data를 리스트로 넣는다. \n",
    "* `reduce(function, data)`: function을 실행할 때 마다 결과의 수가 감소. 최종적으로 하나의 수가 남는다. 대표적인 것이 counting(예를 들어 뉴스그룹. 몇 십 년치 데이터면 컴퓨터 몇 십대인데 이럴 경우에)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  10,  20,  30,  40,  50,  60,  70,  80,  90, 100])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fahrenheit(T):\n",
    "    return 9 / 5 * T + 32\n",
    "\n",
    "temp = np.arange(0, 110, 10)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<map at 0xb0becf8>,\n",
       " [32.0, 50.0, 68.0, 86.0, 104.0, 122.0, 140.0, 158.0, 176.0, 194.0, 212.0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = map(fahrenheit, temp)\n",
    "F, list(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_prime(primes, n):\n",
    "    for p in primes:\n",
    "        if n % p == 0:\n",
    "            return primes\n",
    "    primes.append(n)\n",
    "    return primes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 11,\n",
       " 13,\n",
       " 17,\n",
       " 19,\n",
       " 23,\n",
       " 29,\n",
       " 31,\n",
       " 37,\n",
       " 41,\n",
       " 43,\n",
       " 47,\n",
       " 53,\n",
       " 59,\n",
       " 61,\n",
       " 67,\n",
       " 71,\n",
       " 73,\n",
       " 79,\n",
       " 83,\n",
       " 89,\n",
       " 97]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(create_prime, np.arange(2, 100), [2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Map \n",
    "\n",
    "* map/reduce 연산을 engine process들에게 맡겨서 동시 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pyprimes(kmax):   #의미 생각하지 말고 소수 구하는 복잡한 함수다 정도만 알아두어라\n",
    "    p = np.zeros(1000)\n",
    "    result = []\n",
    "    if kmax > 1000:\n",
    "        kmax = 1000\n",
    "    k = 0\n",
    "    n = 2\n",
    "    while k < kmax:\n",
    "        i = 0\n",
    "        while i < k and n % p[i] != 0:\n",
    "            i = i + 1\n",
    "        if i == k:\n",
    "            p[k] = n\n",
    "            k = k + 1\n",
    "            result.append(n)\n",
    "        n = n + 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time result = map(pyprimes, range(700, 1000))   #도커 안이라서 아래와 이것과 시간이 같게 나올 것이다. 아래 거는 서버에서 돌리면 다를듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.8 s\n"
     ]
    }
   ],
   "source": [
    "%time parallel_result = dview.map_sync(pyprimes, range(700, 1000))   #6명 중 1명이라도 답을 안준다면 안 주고 다 끝나고 나서 끝이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_result == result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "async_result = dview.map_async(pyprimes, range(700, 1000))   #안 끝나도 중간에 제어권 돌려주고 모니터링 알아서 해라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async_result.progress   #몇 명이 완성했는지 알려준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5189, 5197, 5209, 5227, 5231, 5233, 5237, 5261, 5273, 5279]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async_result.get()[0][-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모형 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모형을 분산처리하기 위해서는 sklearn.externals 서브패키지의 `joblib.dump` 명령과 `joblib.load` 명령 사용\n",
    "\n",
    "pikle형태로 지금의 모델 안에 어트리뷰트 가진 형태대로 세이브 하고 긁어오고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ipyparalle 을 사용한 분산 모형 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "news = fetch_20newsgroups(subset=\"all\")\n",
    "n_samples = 3000\n",
    "X_train = news.data[:n_samples]\n",
    "y_train = news.target[:n_samples]\n",
    "\n",
    "model = Pipeline([\n",
    "        ('vect', TfidfVectorizer(stop_words=\"english\", token_pattern=\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\")),\n",
    "        ('svc', SVC()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "import os\n",
    "from sklearn.cross_validation import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Administrator\\\\@수학\\\\160704월_24일차_모형 최적화 Model optimization\\\\news_cv_000.pkl',\n",
       " 'C:\\\\Users\\\\Administrator\\\\@수학\\\\160704월_24일차_모형 최적화 Model optimization\\\\news_cv_001.pkl',\n",
       " 'C:\\\\Users\\\\Administrator\\\\@수학\\\\160704월_24일차_모형 최적화 Model optimization\\\\news_cv_002.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def persist_cv_splits(X, y, K=3, name=\"data\", suffix=\"_cv_%03d.pkl\"):    #데이터를 나눈다. 나눠서 저장한다.\n",
    "    cv_split_filenames = []\n",
    "    cv = KFold(n_samples, K, shuffle=True, random_state=0)\n",
    "    for i, (train, test) in enumerate(cv):\n",
    "        cv_fold = ([X[k] for k in train], y[train],     \n",
    "                   [X[k] for k in test], y[test])\n",
    "        cv_split_filename = name + suffix % i\n",
    "        cv_split_filename = os.path.abspath(cv_split_filename)\n",
    "        joblib.dump(cv_fold, cv_split_filename)\n",
    "        cv_split_filenames.append(cv_split_filename)\n",
    "    return cv_split_filenames\n",
    "\n",
    "cv_filenames = persist_cv_splits(X_train, y_train, name=\"news\")\n",
    "cv_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_evaluation(cv_split_filename, model, params):\n",
    "    from sklearn.externals import joblib\n",
    "    X_train_, y_train_, X_test_, y_test_ = joblib.load(cv_split_filename, mmap_mode=\"c\")\n",
    "    model.set_params(**params)\n",
    "    model.fit(X_train_, y_train_)\n",
    "    test_scores = model.score(X_test_, y_test_)\n",
    "    return test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import ParameterGrid\n",
    "def parallel_grid_search(lb_view, model, cv_split_filenames, param_grid):   #lb_view 엔진에 대한 view. \n",
    "    all_tasks = []\n",
    "    all_parameters = list(ParameterGrid(param_grid))\n",
    "    for i, params in enumerate(all_parameters):\n",
    "        task_for_params = []\n",
    "        for j, cv_split_filename in enumerate(cv_split_filenames):\n",
    "            t = lb_view.apply(compute_evaluation, cv_split_filename, model, params)  #map이랑 유사. apply는 하나짜리 함수 실행. 여기 말고 엔진에 가서 실행\n",
    "            task_for_params.append(t)\n",
    "        all_tasks.append(task_for_params)\n",
    "    return all_parameters, all_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def print_progress(tasks):\n",
    "    progress = np.mean([task.ready() for task_group in tasks for task in task_group])\n",
    "    print(\"{0}:{1}%\".format(datetime.datetime.now(), progress * 100.0))\n",
    "    return int(progress * 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "from ipyparallel import Client\n",
    "client = Client()\n",
    "print(client.ids)\n",
    "lb_view = client.load_balanced_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "parameters = {\n",
    "    \"svc__gamma\": np.logspace(-2, 1, 4),\n",
    "    \"svc__C\": np.logspace(-1, 1, 3),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_parameters, all_tasks = parallel_grid_search(lb_view, model, cv_filenames, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-09-19 09:27:36.316694:0.0%\n",
      "2016-09-19 09:27:37.320708:52.77777777777778%\n",
      "2016-09-19 09:27:38.323524:100.0%\n",
      "finish\n",
      "2.00683\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = datetime.datetime.now()\n",
    "while True:\n",
    "    progress = print_progress(all_tasks)\n",
    "    if progress >= 100:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "print(\"finish\")\n",
    "end_time = datetime.datetime.now()\n",
    "print((end_time - start_time).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
