{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 교차 검증_cross validation = CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상당히 중요하다. 실제로 CV가 안 된 경우는 overfitting이 됐을 가능성이 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모형 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "회귀 모형을 만든 다음에는 모수 추정(parameter fitting) 즉 트레이닝(training)에 사용되지 않은 새로운 독립 변수 데이터를 사용하여 최종 검증(final test)을 하게 된다. 최종 검증 후 모형의 성능은 다음과 같은 요소에 의해 결정된다.\n",
    "\n",
    "* 편향 오차(bias): 새로운 데이터(test data)에 대해서 평균 오차의 크기가 얼마나 작은가?\n",
    "* 오차 분산(variance): 새로운 데이터(test data)에 대해 오차의 크기가 얼마나 달라지는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 교차 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모형 성능 중에서 분산을 계산하려면 검증 데이터 셋이 복수개가 있어야 한다. 그러나 실제로는 데이터의 수는 유한하므로 이 데이터를 복수개의 데이터 셋으로 나누어 여러번 검증하는 방식을 사용한다. 이를 교차 검증(cross-validation)이라고 한다.\n",
    "\n",
    "<img src=\"https://datascienceschool.net/upfiles/91482d91f55b43dd861ffc0ebf43e75b.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 점수가 많이 안 달라져야 한다.\n",
    "* 얼마나 흔들리는가를 보는 것이니까 흔들리지 않는 것을 봐야 한다.\n",
    "* 단순히 R스퀘어를 구하는 것이 아니라 얼마나 흔들리는가를 판단하기 위해서\n",
    "* 어쩌다 잘 본 것이 될 수 있기 때문에\n",
    "* 점수만 얘기하는 것이 아니라 점수의 분포를 얘기하는 것이 CV의 핵심이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn의 교차 검증 기능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* data를 train set과 test set으로 단순 분리\n",
    " * data splitter\n",
    "   * `train_test_split()` 명령\n",
    "\n",
    "\n",
    "* 복수의 test set 준비\n",
    " * cross validation iterator\n",
    "   * `KFold`\n",
    "   * `StratifiedKFold`\n",
    "   * `LabelKFold`\n",
    "   * `LeaveOneOut`\n",
    "   * `LeavePOut`\n",
    "   * `LeaveOneLabelOut`\n",
    "   * `LeavePLabelOut`\n",
    "   * `ShuffleSplit`\n",
    "   * `LabelShuffleSplit`\n",
    " \n",
    " \n",
    "* 복수의 test set 사용하여 평가 과정 반복\n",
    " * cross validation calculator\n",
    "   * `cross_val_score()` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단순 데이터 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_test_split()` 명령은 데이터를 단순히 트레이닝 데이터와 테스트 데이터로 분리한다.\n",
    "\n",
    "\n",
    "* 인수\n",
    " * arrays : 데이터\n",
    " * test_size : 테스트 데이터 사이즈\n",
    " * train_size :  사이즈\n",
    " * random_state : 난수 시드\n",
    "\n",
    "* 반환값\n",
    " * 배열 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.arange(10).reshape((5, 2))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.arange(5)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 5],\n",
       "       [0, 1],\n",
       "       [6, 7]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이 방법을 가장 많이 쓰인다.\n",
    "* train_test_split()가 알아서 쓰인다.\n",
    "* KFold의 K를 늘리면 늘릴수록 스코어의 값이 커진다. N개의 데이터가 있으면 K만큼 쪼갠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold CV(cross-validation) 방법은 데이터 셋을 K개의 sub-set로 분리하는 방법이다. 분리된 K개의 sub-set 중 하나만 제외한 K-1개의 sub-sets를 training set으로 이용하여 K개의 모형 추정한다. \n",
    " \n",
    "<img src=\"https://docs.google.com/drawings/d/1JdgUDzuE75LBxqT5sKOhlPgP6umEkvD3Sm-gKnu-jqA/pub?w=762&h=651\" style=\"margin: 0 auto 0 auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn 의 cross_validation 서브 패키지는 K-Fold를 위한 `KFold` 클래스를 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[  0  10]\n",
      " [ 20  30]\n",
      " [ 40  50]\n",
      " [ 60  70]\n",
      " [ 80  90]\n",
      " [100 110]\n",
      " [120 130]\n",
      " [140 150]\n",
      " [160 170]\n",
      " [180 190]\n",
      " [200 210]\n",
      " [220 230]\n",
      " [240 250]\n",
      " [260 270]\n",
      " [280 290]\n",
      " [300 310]\n",
      " [320 330]\n",
      " [340 350]\n",
      " [360 370]\n",
      " [380 390]]\n",
      "y:\n",
      "[ 1.  1.  1.  1.  1.  2.  2.  2.  2.  2.  3.  3.  3.  3.  3.  4.  4.  4.\n",
      "  4.  4.]\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "X = np.arange(8 * N).reshape(-1, 2) * 10\n",
    "y = np.hstack([np.ones(N), np.ones(N) * 2, np.ones(N) * 3, np.ones(N) * 4])\n",
    "print(\"X:\\n\", X, sep=\"\")\n",
    "print(\"y:\\n\", y, sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test y: [ 1.  1.  1.  1.  1.  2.  2.]\n",
      "................................................................................\n",
      "train y: [ 2.  2.  2.  3.  3.  3.  3.  3.  4.  4.  4.  4.  4.]\n",
      "================================================================================\n",
      "test y: [ 2.  2.  2.  3.  3.  3.  3.]\n",
      "................................................................................\n",
      "train y: [ 1.  1.  1.  1.  1.  2.  2.  3.  4.  4.  4.  4.  4.]\n",
      "================================================================================\n",
      "test y: [ 3.  4.  4.  4.  4.  4.]\n",
      "................................................................................\n",
      "train y: [ 1.  1.  1.  1.  1.  2.  2.  2.  2.  2.  3.  3.  3.  3.]\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "cv = KFold(len(X), n_folds=3, random_state=0)\n",
    "for train_index, test_index in cv:\n",
    "    print(\"test y:\", y[test_index])\n",
    "    print(\".\" * 80)\n",
    "    print(\"train y:\", y[train_index])\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-One-Out (LOO)\n",
    "\n",
    "* 하나의 sample만을 test set으로 남긴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test X: [[ 0 10]]\n",
      "................................................................................\n",
      "test y: [ 1.]\n",
      "================================================================================\n",
      "test X: [[20 30]]\n",
      "................................................................................\n",
      "test y: [ 1.]\n",
      "================================================================================\n",
      "test X: [[40 50]]\n",
      "................................................................................\n",
      "test y: [ 1.]\n",
      "================================================================================\n",
      "test X: [[60 70]]\n",
      "................................................................................\n",
      "test y: [ 1.]\n",
      "================================================================================\n",
      "test X: [[80 90]]\n",
      "................................................................................\n",
      "test y: [ 1.]\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import LeaveOneOut\n",
    "cv = LeaveOneOut(5)\n",
    "for train_indx, test_index in cv:\n",
    "    print(\"test X:\", X[test_index])\n",
    "    print(\".\" * 80)\n",
    "    print(\"test y:\", y[test_index])\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K-Fold\n",
    "\n",
    "* target class가 어느 한 data set에 몰리지 않도록 한다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* y값의 비중을 맞추어서 뽑는다.\n",
    "* 예를 들어서 1,2,3,4,5번의 객관식 문제 답 골고루 내는 것\n",
    "* y값을 넣어줘야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test X:\n",
      " [[  0  10]\n",
      " [ 20  30]\n",
      " [100 110]\n",
      " [120 130]\n",
      " [200 210]\n",
      " [220 230]\n",
      " [300 310]\n",
      " [320 330]]\n",
      "................................................................................\n",
      "test y: [ 1.  1.  2.  2.  3.  3.  4.  4.]\n",
      "================================================================================\n",
      "test X:\n",
      " [[ 40  50]\n",
      " [ 60  70]\n",
      " [140 150]\n",
      " [160 170]\n",
      " [240 250]\n",
      " [260 270]\n",
      " [340 350]\n",
      " [360 370]]\n",
      "................................................................................\n",
      "test y: [ 1.  1.  2.  2.  3.  3.  4.  4.]\n",
      "================================================================================\n",
      "test X:\n",
      " [[ 80  90]\n",
      " [180 190]\n",
      " [280 290]\n",
      " [380 390]]\n",
      "................................................................................\n",
      "test y: [ 1.  2.  3.  4.]\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(y, n_folds=3, random_state=0)\n",
    "\n",
    "for train_index, test_index in cv:\n",
    "    print(\"test X:\\n\", X[test_index])\n",
    "    print(\".\" * 80)\n",
    "    print(\"test y:\", y[test_index])\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label K-Fold\n",
    "\n",
    "* 같은 label이 test와 train에 동시에 들어가지 않게 조절\n",
    "* label에 의한 영향을 최소화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 아까랑 반대 케이스. 한쪽을 몰아넣고 싶다. \n",
    "* y가 클래스 값일때만 쓸 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  y: [ 1.  1.  1.  1.  1.  4.  4.  4.  4.  4.]\n",
      "................................................................................\n",
      "train y: [ 2.  2.  2.  2.  2.  3.  3.  3.  3.  3.]\n",
      "================================================================================\n",
      "test  y: [ 3.  3.  3.  3.  3.]\n",
      "................................................................................\n",
      "train y: [ 1.  1.  1.  1.  1.  2.  2.  2.  2.  2.  4.  4.  4.  4.  4.]\n",
      "================================================================================\n",
      "test  y: [ 2.  2.  2.  2.  2.]\n",
      "................................................................................\n",
      "train y: [ 1.  1.  1.  1.  1.  3.  3.  3.  3.  3.  4.  4.  4.  4.  4.]\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import LabelKFold\n",
    "cv = LabelKFold(y, n_folds=3)\n",
    "for train_index, test_index in cv:\n",
    "    print(\"test  y:\", y[test_index])\n",
    "    print(\".\" * 80 )        \n",
    "    print(\"train y:\", y[train_index])\n",
    "    print(\"=\" * 80 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ShuffleSplit\n",
    "\n",
    "* 중복된 데이터를 허용\n",
    "* 지금까지는 정확하게 뚝 잘라서 썼는데 이거는 중복된 데이터를 허용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test X: [[40 50]]\n",
      "====================\n",
      "test X: [[20 30]]\n",
      "====================\n",
      "test X: [[20 30]]\n",
      "====================\n",
      "test X: [[20 30]]\n",
      "====================\n",
      "test X: [[60 70]]\n",
      "====================\n",
      "test X: [[80 90]]\n",
      "====================\n",
      "test X: [[ 0 10]]\n",
      "====================\n",
      "test X: [[20 30]]\n",
      "====================\n",
      "test X: [[40 50]]\n",
      "====================\n",
      "test X: [[60 70]]\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import ShuffleSplit\n",
    "cv = ShuffleSplit(5)\n",
    "for train_index, test_index in cv:\n",
    "    print(\"test X:\", X[test_index])\n",
    "    print(\"=\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 특별한 문제가 있지 않는 이상 KFold만 쓴다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 교차 평가 시행 \n",
    "\n",
    "CV는 단순히 데이터 셋을 나누는 역할을 수행할 뿐이다. 실제로 모형의 성능(편향 오차 및 분산)을 구하려면 이렇게 나누어진 데이터셋을 사용하여 평가를 반복하여야 한다. 이 과정을 자동화하는 명령이 `cross_val_score()` 이다.\n",
    "\n",
    "\n",
    "* `cross_val_score(estimator, X, y=None, scoring=None, cv=None)` \n",
    " * cross validation iterator `cv`를 이용하여 `X`, `y` data 를 분할하고 `estimator`에 넣어서 `scoring` metric을 구하는 과정을 반복\n",
    "\n",
    "\n",
    "* 인수\n",
    " * estimator : ‘fit’메서드가 제공되는 모형\n",
    " * X : 배열\n",
    "   * 독립 변수 데이터\n",
    " * y : 배열\n",
    "   * 종속 변수 데이터\n",
    " * scoring : 문자열\n",
    "   * 성능 검증에 사용할 함수\n",
    " * cv : Cross Validator\n",
    "   * None 이면 디폴트인  3-폴드 CV\n",
    "   * 숫자 K  이면 K-폴드 CV\n",
    "   * Cross Validator 클래스 객체\n",
    "\n",
    "* 반환값\n",
    "  * scores \n",
    "      * 계산된 성능 값의 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y, coef = make_regression(n_samples=1000, n_features=1, noise=20, coef=True, random_state=0)\n",
    "model = LinearRegression()\n",
    "cv = KFold(1000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 301.58271911,  341.91498985,  410.58098438,  499.68109613,\n",
       "        461.00979825,  384.106544  ,  434.90159273,  377.65506997,\n",
       "        366.60959935,  371.14031438])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = np.zeros(10)\n",
    "for i, (train_index, test_index) in enumerate(cv):\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores[i] = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-301.58271911, -341.91498985, -410.58098438, -499.68109613,\n",
       "       -461.00979825, -384.106544  , -434.90159273, -377.65506997,\n",
       "       -366.60959935, -371.14031438])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "cross_val_score(model, X, y, \"mean_squared_error\", cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 회귀 분석에 사용되는 성능 함수들"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `r2_score(y_true, y_pred[, ...])`:\tR^2 (coefficient of determination) regression score function.\n",
    "* `explained_variance_score(y_true, y_pred)`:\tExplained variance regression score function\n",
    "* `mean_squared_error(y_true, y_pred[, ...])`:\tMean squared error regression loss\n",
    "* `mean_absolute_error(y_true, y_pred)`:\tMean absolute error regression loss\n",
    "* `median_absolute_error(y_true, y_pred)`:\tMedian absolute error regression loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
